"""
ì„œìš¸ ì•„íŒŒíŠ¸ ê²€ìƒ‰ ì•± (Streamlit)
"""
import os
import re
from difflib import SequenceMatcher

import pandas as pd
import streamlit as st
import folium
from streamlit_folium import st_folium

from crawler import SeoulApartmentCrawler
from utils import extract_dong

# ìƒˆë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ì„¸ì…˜ì— ë„£ì–´ë‘ëŠ” í‚¤ (Cloudì—ì„œ íŒŒì¼ ì €ì¥ì´ ì•ˆ ë¼ë„ ìƒˆë¡œê³ ì¹¨ ë°˜ì˜)
SESSION_KEY_APARTMENT_DATA = "apartment_data"
# ë©”ì¸ ì•„íŒŒíŠ¸(ì‹¤ê±°ë˜ê°€) ë‹¨ì§€ëª… ìœ ì‚¬ë„ ë§¤ì¹­ ì„ê³„ê°’ (0~1)
MAIN_APT_SIMILARITY_THRESHOLD = 0.85


def normalize_dong(dong):
    """ë™ í‘œê¸° ì •ê·œí™”: 'ì—­ì‚¼2ë™' â†’ 'ì—­ì‚¼ë™', 'ì‚¼ì„±1ë™' â†’ 'ì‚¼ì„±ë™' (ìˆ«ì ì œê±°)."""
    if dong is None or (isinstance(dong, float) and pd.isna(dong)):
        return ""
    s = str(dong).strip()
    if not s:
        return ""
    return re.sub(r"\d+ë™$", "ë™", s)


def normalize_apt(name):
    """ë‹¨ì§€ëª… ì •ê·œí™”: ê³µë°± collapse, ì•ë’¤ ê³µë°± ì œê±°."""
    if name is None or (isinstance(name, float) and pd.isna(name)):
        return ""
    return " ".join(str(name).strip().split())


def enrich_with_main_apt(df: pd.DataFrame, main_path: str) -> pd.DataFrame:
    """
    ë©”ì¸ ì•„íŒŒíŠ¸ CSVì™€ ë™ ì •ê·œí™” + ë‹¨ì§€ëª… ìœ ì‚¬ë„ ë§¤ì¹­ìœ¼ë¡œ left join.
    ë§¤ì¹­ë˜ë©´ í‰ìˆ˜, ì‹¤ê±°ë˜ê°€, ê¸°ì¤€ì—°ì›”ì¼ ì»¬ëŸ¼ ì¶”ê°€; ì•ˆ ë˜ë©´ ê³µë€.
    """
    if not os.path.exists(main_path) or df.empty:
        return df
    try:
        main = pd.read_csv(main_path, encoding="utf-8-sig")
        main = main[["êµ¬", "ë™", "ì•„íŒŒíŠ¸ëª…", "í‰ìˆ˜", "ì‹¤ê±°ë˜ê°€", "ê¸°ì¤€ì—°ì›”ì¼"]].drop_duplicates(
            subset=["êµ¬", "ë™", "ì•„íŒŒíŠ¸ëª…"], keep="first"
        )
    except Exception:
        return df
    main["norm_ë™"] = main["ë™"].apply(normalize_dong)
    main["norm_ì•„íŒŒíŠ¸ëª…"] = main["ì•„íŒŒíŠ¸ëª…"].apply(normalize_apt)
    # (êµ¬, norm_ë™)ë³„ í›„ë³´ ë¦¬ìŠ¤íŠ¸
    main_by_key = {}
    for _, row in main.iterrows():
        key = (row["êµ¬"], row["norm_ë™"])
        if key not in main_by_key:
            main_by_key[key] = []
        main_by_key[key].append(row)

    df = df.copy()
    df["í‰ìˆ˜"] = None
    df["ì‹¤ê±°ë˜ê°€"] = None
    df["ê¸°ì¤€ì—°ì›”ì¼"] = None
    if "ìì¹˜êµ¬" not in df.columns or "ë™" not in df.columns or "ì•„íŒŒíŠ¸ëª…" not in df.columns:
        return df
    for i in df.index:
        gu = df.at[i, "ìì¹˜êµ¬"]
        dong = df.at[i, "ë™"]
        apt = df.at[i, "ì•„íŒŒíŠ¸ëª…"]
        norm_dong = normalize_dong(dong)
        norm_apt = normalize_apt(apt)
        candidates = main_by_key.get((gu, norm_dong), [])
        if not candidates:
            continue
        best = max(
            candidates,
            key=lambda c: SequenceMatcher(None, norm_apt, c["norm_ì•„íŒŒíŠ¸ëª…"]).ratio(),
        )
        sim = SequenceMatcher(None, norm_apt, best["norm_ì•„íŒŒíŠ¸ëª…"]).ratio()
        if sim >= MAIN_APT_SIMILARITY_THRESHOLD:
            df.at[i, "í‰ìˆ˜"] = best["í‰ìˆ˜"]
            df.at[i, "ì‹¤ê±°ë˜ê°€"] = best["ì‹¤ê±°ë˜ê°€"]
            df.at[i, "ê¸°ì¤€ì—°ì›”ì¼"] = best["ê¸°ì¤€ì—°ì›”ì¼"]
    return df


def preprocess_apartment_df(df: pd.DataFrame) -> pd.DataFrame:
    """CSV/APIì—ì„œ ì½ì€ dfì— ë™ì¼í•œ ì „ì²˜ë¦¬(ë™ ì¶”ê°€, ì„ëŒ€Â·ì˜¤í”¼ìŠ¤í…” ì œì™¸ ë“±) ì ìš©."""
    if df.empty:
        return df
    df = df.copy()
    if "ë™" not in df.columns:
        if "ì›ë³¸_EMD_ADDR" in df.columns:
            df["ë™"] = df["ì›ë³¸_EMD_ADDR"].apply(
                lambda x: str(x).strip() if pd.notna(x) and str(x).strip() and str(x).strip() != "nan" else None
            )
        else:
            df["ë™"] = df["ì£¼ì†Œ"].apply(extract_dong)
    if "ì•„íŒŒíŠ¸ëª…" in df.columns:
        df = df[~df["ì•„íŒŒíŠ¸ëª…"].astype(str).str.contains("ì„ëŒ€", na=False)]
    if "ì›ë³¸_CMPX_CLSF" in df.columns:
        df = df[df["ì›ë³¸_CMPX_CLSF"].astype(str).str.contains("ì•„íŒŒíŠ¸", na=False)]
    if "ì•„íŒŒíŠ¸ëª…" in df.columns:
        df = df[~df["ì•„íŒŒíŠ¸ëª…"].astype(str).str.contains("ì˜¤í”¼ìŠ¤í…”", na=False, case=False)]
    if "ë™" in df.columns:
        df["ë™"] = df["ë™"].replace("ë‹µì‹­ë¦¬1ë™", "ë‹µì‹­ë¦¬ë™")
    return df


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì„œìš¸ ì•„íŒŒíŠ¸ ê²€ìƒ‰",
    page_icon="ğŸ¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì œëª©
# st.title("ğŸ¢ ì„œìš¸ ì•„íŒŒíŠ¸ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
# st.markdown("---")

# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ (ìºì‹±). ì„¸ì…˜ì— ìƒˆë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©."""
    # 1) ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìˆ˜ì§‘í•œ ë°ì´í„°ê°€ ì„¸ì…˜ì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (Cloudì—ì„œ íŒŒì¼ ì €ì¥ ì•ˆ ë¼ë„ ë™ì‘)
    if SESSION_KEY_APARTMENT_DATA in st.session_state:
        df = st.session_state[SESSION_KEY_APARTMENT_DATA]
        if df is not None and not df.empty:
            return df, "metadata", len(df)

    crawler = SeoulApartmentCrawler()
    # 2) CSV ë˜ëŠ” ìƒ˜í”Œ
    if os.path.exists("seoul_apartments_metadata.csv"):
        df = crawler.load_from_csv("seoul_apartments_metadata.csv")
        data_type = "metadata"
    elif os.path.exists("seoul_apartments.csv"):
        df = crawler.load_from_csv("seoul_apartments.csv")
        data_type = "sample" if "ì•„íŒŒíŠ¸ëª…" not in df.columns else "normal"
    else:
        df = crawler.generate_sample_data(num_samples=500)
        crawler.save_to_csv(df, "seoul_apartments.csv")
        data_type = "generated"

    df = preprocess_apartment_df(df)
    return df, data_type, len(df)


# ë°ì´í„° ë¡œë“œ
df, data_type, data_count = load_data()

# ë°ì´í„° ë¡œë“œ ë©”ì‹œì§€ í‘œì‹œ (ìºì‹œ í•¨ìˆ˜ ë°–ì—ì„œ)
if data_type == "metadata":
    st.toast(f"ì‹¤ì œ ì•„íŒŒíŠ¸ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({data_count}ê±´)", icon="âœ…")
elif data_type == "sample":
    st.toast("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.", icon="âš ï¸")
elif data_type == "generated":
    st.toast("ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...", icon="â„¹ï¸")

# ë™ ì •ë³´ ì¶”ê°€ (ì—†ìœ¼ë©´ ìƒì„±)
if "ë™" not in df.columns:
    df["ë™"] = df["ì£¼ì†Œ"].apply(extract_dong)

# ë©”ì¸ ì•„íŒŒíŠ¸(ì‹¤ê±°ë˜ê°€) CSVì™€ ë™ ì •ê·œí™” + ë‹¨ì§€ëª… ìœ ì‚¬ë„ ë§¤ì¹­ìœ¼ë¡œ í‰ìˆ˜/ì‹¤ê±°ë˜ê°€/ê¸°ì¤€ì—°ì›”ì¼ ì¶”ê°€
df = enrich_with_main_apt(df, "seoul_disrict_main_apt.csv")

# ì‚¬ì´ë“œë°” í•„í„°
st.sidebar.header("ğŸ” ê²€ìƒ‰ í•„í„°")

# ì´ˆê¸°í™” ë²„íŠ¼ (ìì¹˜êµ¬ ì œì™¸í•˜ê³  ëª¨ë“  í•„í„° ì´ˆê¸°í™”)
if st.sidebar.button("ğŸ”„ í•„í„° ì´ˆê¸°í™”", width="stretch"):
    # í•„í„° ê´€ë ¨ session_state í‚¤ë“¤ ì´ˆê¸°í™” (ìì¹˜êµ¬ ì œì™¸)
    filter_keys = ['dong', 'year_range', 'household', 'hallway', 'distance', 'subway']
    for key in filter_keys:
        if key in st.session_state:
            del st.session_state[key]
    st.rerun()

# ìì¹˜êµ¬ì™€ ë™ í•„í„° (ë³‘ë ¬ ë°°ì¹˜)
col_district, col_dong = st.sidebar.columns(2)

with col_district:
    districts_list = df["ìì¹˜êµ¬"].dropna().unique().tolist()
    districts = ["ì „ì²´"] + sorted([str(x) for x in districts_list if pd.notna(x) and str(x).strip()])
    # ê¸°ë³¸ê°’ì„ ë™ëŒ€ë¬¸êµ¬ë¡œ ì„¤ì • (ë™ëŒ€ë¬¸êµ¬ê°€ ìˆìœ¼ë©´)
    default_district = "ë™ëŒ€ë¬¸êµ¬" if "ë™ëŒ€ë¬¸êµ¬" in districts else "ì „ì²´"
    selected_district = st.selectbox("ìì¹˜êµ¬", districts, index=districts.index(default_district) if default_district in districts else 0)

with col_dong:
    # ë™ í•„í„° (ìì¹˜êµ¬ ì„ íƒ ì‹œ í•´ë‹¹ ìì¹˜êµ¬ì˜ ë™ë§Œ í‘œì‹œ) - ë™ì  ê°±ì‹ 
    if selected_district != "ì „ì²´":
        district_df = df[df["ìì¹˜êµ¬"] == selected_district]
        dong_list = district_df["ë™"].dropna().unique().tolist()
        dongs = ["ì „ì²´"] + sorted([str(x) for x in dong_list if pd.notna(x) and str(x).strip()])
    else:
        dong_list = df["ë™"].dropna().unique().tolist()
        dongs = ["ì „ì²´"] + sorted([str(x) for x in dong_list if pd.notna(x) and str(x).strip()])
    
    # ì´ˆê¸°í™” ì‹œ ë™ì€ "ì „ì²´"ë¡œ
    selected_dong = st.selectbox("ë™", dongs, index=0, key="dong")

# í•„í„°ë§ëœ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ìŠ¬ë¼ì´ë” ë²”ìœ„ ê³„ì‚° (ìì¹˜êµ¬ > ë™ ìˆœì„œë¡œ ë™ì  ê°±ì‹ )
if selected_district != "ì „ì²´":
    filter_base = df[df["ìì¹˜êµ¬"] == selected_district]
    if selected_dong != "ì „ì²´":
        filter_base = filter_base[filter_base["ë™"] == selected_dong]
else:
    filter_base = df.copy()

# ê±´ì¶•ì—°ë„ í•„í„° (í•„í„°ë§ëœ ë°ì´í„° ê¸°ì¤€) - ë™ì  ê°±ì‹ 
year_data = filter_base["ê±´ì¶•ì—°ë„"].dropna()
if len(year_data) > 0:
    min_year = int(year_data.min())
    max_year = int(year_data.max())
    # ì´ˆê¸°í™” ì‹œ ì „ì²´ ë²”ìœ„ë¡œ
    default_year_range = (min_year, max_year)
    year_range = st.sidebar.slider(
        "ê±´ì¶•ì—°ë„ ë²”ìœ„",
        min_value=min_year,
        max_value=max_year,
        value=default_year_range,
        step=1,
        key="year_range"
    )
else:
    year_range = (1900, 2025)

# ì„¸ëŒ€ìˆ˜ í•„í„° (ìŠ¬ë¼ì´ë”) - ë™ì  ê°±ì‹ , ê¸°ë³¸ ìµœì†Œ 300ì„¸ëŒ€ ì´ìƒ
household_data = filter_base["ì„¸ëŒ€ìˆ˜"].dropna()
if len(household_data) > 0:
    min_household = int(household_data.min())
    max_household = int(household_data.max())
    default_household_low = min(max(300, min_household), max_household)
    default_household_range = (default_household_low, max_household)
    household_range = st.sidebar.slider(
        "ì„¸ëŒ€ìˆ˜ ë²”ìœ„",
        min_value=min_household,
        max_value=max_household,
        value=default_household_range,
        step=100,
        key="household"
    )
else:
    household_range = (0, 10000)

# ë³µë„/ê³„ë‹¨ì‹ í•„í„° - ë™ì  ê°±ì‹ 
hallway_types_list = filter_base["ë³µë„ê³„ë‹¨ì‹"].dropna().unique().tolist()
hallway_types = ["ì „ì²´"] + sorted([str(x) for x in hallway_types_list if pd.notna(x)])
# ì´ˆê¸°í™” ì‹œ "ì „ì²´"ë¡œ
selected_hallway = st.sidebar.selectbox("ë³µë„/ê³„ë‹¨ì‹", hallway_types, index=0, key="hallway")

# í‰í˜• í•„í„° ì œê±° (ì‚¬ìš©ì ìš”ì²­)

# ì§€í•˜ì² ì—­ ê±°ë¦¬ í•„í„° (ìŠ¬ë¼ì´ë”) - ë™ì  ê°±ì‹ 
distance_data = filter_base["ì§€í•˜ì² ì—­ê±°ë¦¬_km"].dropna()
if len(distance_data) > 0:
    min_distance = float(distance_data.min())
    max_distance = float(distance_data.max())
    # ì´ˆê¸°í™” ì‹œ ì „ì²´ ë²”ìœ„ë¡œ
    default_distance_range = (min_distance, max_distance)
    distance_range = st.sidebar.slider(
        "ì§€í•˜ì² ì—­ ê±°ë¦¬ ë²”ìœ„ (km)",
        min_value=min_distance,
        max_value=max_distance,
        value=default_distance_range,
        step=0.01,
        format="%.2f",
        key="distance"
    )
else:
    distance_range = (0.0, 10.0)

# ì§€í•˜ì² ì—­ ì„ íƒ í•„í„° (ìì¹˜êµ¬/ë™ ì„ íƒ ì‹œ í•´ë‹¹ ì§€ì—­ ë‚´ ì§€í•˜ì² ì—­ë§Œ í‘œì‹œ) - ë™ì  ê°±ì‹ 
if selected_district != "ì „ì²´":
    # ì„ íƒëœ ìì¹˜êµ¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë§Œ í•„í„°ë§
    district_df = df[df["ìì¹˜êµ¬"] == selected_district]
    if selected_dong != "ì „ì²´":
        district_df = district_df[district_df["ë™"] == selected_dong]
    subway_stations_list = district_df["ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­"].dropna().unique().tolist()
else:
    # ì „ì²´ ë°ì´í„°ì—ì„œ ì§€í•˜ì² ì—­ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    subway_stations_list = df["ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­"].dropna().unique().tolist()

# ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬ (í•œê¸€ ì •ë ¬)
subway_stations = ["ì „ì²´"] + sorted(
    [str(x) for x in subway_stations_list if pd.notna(x) and str(x).strip()],
    key=lambda x: x  # í•œê¸€ì€ ê¸°ë³¸ ì •ë ¬ë¡œ ê°€ë‚˜ë‹¤ìˆœ ì •ë ¬ë¨
)
# ì´ˆê¸°í™” ì‹œ "ì „ì²´"ë¡œ
selected_subway = st.sidebar.selectbox("ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­", subway_stations, index=0, key="subway")

# í•„í„° ì ìš©
filtered_df = df.copy()

if selected_district != "ì „ì²´":
    filtered_df = filtered_df[filtered_df["ìì¹˜êµ¬"] == selected_district]

# ë™ í•„í„° ì ìš©
if selected_dong != "ì „ì²´":
    filtered_df = filtered_df[filtered_df["ë™"] == selected_dong]

# ê±´ì¶•ì—°ë„ í•„í„° (NaN ê°’ ì²˜ë¦¬)
if len(year_data) > 0:
    filtered_df = filtered_df[
        (filtered_df["ê±´ì¶•ì—°ë„"].notna()) &
        (filtered_df["ê±´ì¶•ì—°ë„"] >= year_range[0]) &
        (filtered_df["ê±´ì¶•ì—°ë„"] <= year_range[1])
    ]

# ì„¸ëŒ€ìˆ˜ í•„í„° (NaN ê°’ ì²˜ë¦¬) - ìŠ¬ë¼ì´ë” ë²”ìœ„ ì ìš©
if len(household_data) > 0:
    filtered_df = filtered_df[
        (filtered_df["ì„¸ëŒ€ìˆ˜"].notna()) &
        (filtered_df["ì„¸ëŒ€ìˆ˜"] >= household_range[0]) &
        (filtered_df["ì„¸ëŒ€ìˆ˜"] <= household_range[1])
    ]

if selected_hallway != "ì „ì²´":
    filtered_df = filtered_df[filtered_df["ë³µë„ê³„ë‹¨ì‹"] == selected_hallway]

# í‰í˜• í•„í„° ì œê±° (ì‚¬ìš©ì ìš”ì²­)

# ì§€í•˜ì² ì—­ ê±°ë¦¬ í•„í„° (NaN ê°’ ì²˜ë¦¬) - ìŠ¬ë¼ì´ë” ë²”ìœ„ ì ìš©
if len(distance_data) > 0:
    filtered_df = filtered_df[
        (filtered_df["ì§€í•˜ì² ì—­ê±°ë¦¬_km"].notna()) &
        (filtered_df["ì§€í•˜ì² ì—­ê±°ë¦¬_km"] >= distance_range[0]) &
        (filtered_df["ì§€í•˜ì² ì—­ê±°ë¦¬_km"] <= distance_range[1])
    ]

if selected_subway != "ì „ì²´":
    filtered_df = filtered_df[filtered_df["ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­"] == selected_subway]

# ê²°ê³¼ í‘œì‹œ
st.write(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(filtered_df)}ê°œ")

if len(filtered_df) > 0:
    # í†µê³„ ì •ë³´
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        year_data = filtered_df['ê±´ì¶•ì—°ë„'].dropna()
        if len(year_data) > 0:
            st.metric("í‰ê·  ê±´ì¶•ì—°ë„", f"{int(year_data.mean())}ë…„")
        else:
            st.metric("í‰ê·  ê±´ì¶•ì—°ë„", "N/A")
    with col2:
        household_data = filtered_df['ì„¸ëŒ€ìˆ˜'].dropna()
        if len(household_data) > 0:
            st.metric("í‰ê·  ì„¸ëŒ€ìˆ˜", f"{int(household_data.mean())}ì„¸ëŒ€")
        else:
            st.metric("í‰ê·  ì„¸ëŒ€ìˆ˜", "N/A")
    with col3:
        # ì„¸ëŒ€ë‹¹ í‰ê·  í‰í˜• í‘œì‹œ
        if "ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•" in filtered_df.columns:
            avg_pyeong_data = filtered_df["ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•"].dropna()
            if len(avg_pyeong_data) > 0:
                st.metric("í‰ê·  í‰í˜• (ì„¸ëŒ€ë‹¹)", f"{avg_pyeong_data.mean():.1f}í‰")
            else:
                # ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•ì´ ì—†ìœ¼ë©´ í‰í˜• ì»¬ëŸ¼ ì‚¬ìš©
                if "í‰í˜•" in filtered_df.columns:
                    pyeong_data = filtered_df["í‰í˜•"].dropna()
                    if len(pyeong_data) > 0:
                        st.metric("í‰ê·  í‰í˜•", f"{pyeong_data.mean():.1f}í‰")
                    else:
                        st.metric("í‰ê·  í‰í˜•", "N/A")
                else:
                    st.metric("í‰ê·  í‰í˜•", "N/A")
        else:
            # ì„¸ëŒ€ë‹¹í‰ê· í‰í˜• ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ í‰í˜• ì»¬ëŸ¼ ì‚¬ìš©
            if "í‰í˜•" in filtered_df.columns:
                pyeong_data = filtered_df["í‰í˜•"].dropna()
                if len(pyeong_data) > 0:
                    st.metric("í‰ê·  í‰í˜•", f"{pyeong_data.mean():.1f}í‰")
                else:
                    st.metric("í‰ê·  í‰í˜•", "N/A")
            else:
                st.metric("í‰ê·  í‰í˜•", "N/A")
    with col4:
        if "ì£¼ì°¨ëŒ€ìˆ˜" in filtered_df.columns:
            parking_data = filtered_df["ì£¼ì°¨ëŒ€ìˆ˜"].dropna()
            # ì£¼ì°¨ëŒ€ìˆ˜ê°€ 0ì¸ ê²½ìš°ë„ í¬í•¨ (0ì€ ìœ íš¨í•œ ê°’)
            parking_data = parking_data[parking_data >= 0]  # ìŒìˆ˜ ì œì™¸ë§Œ
            if len(parking_data) > 0:
                st.metric("í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜", f"{int(parking_data.mean())}ëŒ€")
            else:
                st.metric("í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜", "N/A")
        else:
            st.metric("í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜", "N/A")
    with col5:
        if "ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜" in filtered_df.columns:
            parking_per_hh_data = filtered_df["ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜"].dropna()
            if len(parking_per_hh_data) > 0:
                st.metric("í‰ê·  ì„¸ëŒ€ë‹¹ ì£¼ì°¨ë©´ìˆ˜", f"{parking_per_hh_data.mean():.2f}ë©´")
            else:
                st.metric("í‰ê·  ì„¸ëŒ€ë‹¹ ì£¼ì°¨ë©´ìˆ˜", "N/A")
        else:
            distance_data = filtered_df["ì§€í•˜ì² ì—­ê±°ë¦¬_km"].dropna()
            if len(distance_data) > 0:
                st.metric("í‰ê·  ì§€í•˜ì²  ê±°ë¦¬", f"{distance_data.mean():.2f}km")
            else:
                st.metric("í‰ê·  ì§€í•˜ì²  ê±°ë¦¬", "N/A")
    
    st.markdown("---")
    
    # íƒ­ ìƒì„±
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ ëª©ë¡", "ğŸ—ºï¸ ì§€ë„", "ğŸ“ˆ í†µê³„"])
    
    with tab1:
        # ê¸°ë³¸ ì •ë ¬: ê±´ì¶•ì—°ë„ ì˜¤ë¦„ì°¨ìˆœ (ì˜¤ë˜ëœìˆœ)
        if "ê±´ì¶•ì—°ë„" in filtered_df.columns:
            sorted_df = filtered_df.sort_values(
                by="ê±´ì¶•ì—°ë„",
                ascending=True,
                na_position='last'  # NaN ê°’ì€ ë§¨ ë’¤ë¡œ
            )
        else:
            sorted_df = filtered_df.copy()
        
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ (í™”ë©´ ì¶œë ¥ìš© ì»¬ëŸ¼ë§Œ í•„í„°ë§)
        # ì›ë³¸ ë°ì´í„°ëŠ” ëª¨ë‘ ì €ì¥ë˜ì–´ ìˆì§€ë§Œ, í™”ë©´ì—ëŠ” í•„ìš”í•œ ì»¬ëŸ¼ë§Œ í‘œì‹œ
        display_columns = []
        
        # ê¸°ë³¸ ì •ë³´
        if "ìì¹˜êµ¬" in sorted_df.columns:
            display_columns.append("ìì¹˜êµ¬")
        if "ë™" in sorted_df.columns:
            display_columns.append("ë™")
        if "ì•„íŒŒíŠ¸ëª…" in sorted_df.columns:
            display_columns.append("ì•„íŒŒíŠ¸ëª…")
        if "ê±´ì¶•ì—°ë„" in sorted_df.columns:
            display_columns.append("ê±´ì¶•ì—°ë„")
        if "ì„¸ëŒ€ìˆ˜" in sorted_df.columns:
            display_columns.append("ì„¸ëŒ€ìˆ˜")
        if "ë³µë„ê³„ë‹¨ì‹" in sorted_df.columns:
            display_columns.append("ë³µë„ê³„ë‹¨ì‹")
        
        # ë©´ì  ì •ë³´ (ì„¸ëŒ€ë‹¹ í‰ê· ë§Œ í‘œì‹œ)
        if "ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•" in sorted_df.columns:
            display_columns.append("ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•")
        # ë©”ì¸ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ (ë™Â·ë‹¨ì§€ëª… ì •ê·œí™”+ìœ ì‚¬ë„ ë§¤ì¹­, ì—†ìœ¼ë©´ ê³µë€)
        if "í‰ìˆ˜" in sorted_df.columns:
            display_columns.append("í‰ìˆ˜")
        if "ì‹¤ê±°ë˜ê°€" in sorted_df.columns:
            display_columns.append("ì‹¤ê±°ë˜ê°€")
        if "ê¸°ì¤€ì—°ì›”ì¼" in sorted_df.columns:
            display_columns.append("ê¸°ì¤€ì—°ì›”ì¼")
        # ì „ìš©ë©´ì ë³„ ì„¸ëŒ€í˜„í™© (í‰í˜•ë³„ ì„¸ëŒ€ìˆ˜ ë¶„í¬)
        if "ì „ìš©ë©´ì 60ã¡ì´í•˜_ì„¸ëŒ€ìˆ˜" in sorted_df.columns:
            display_columns.append("ì „ìš©ë©´ì 60ã¡ì´í•˜_ì„¸ëŒ€ìˆ˜")
        if "ì „ìš©ë©´ì 60_85ã¡_ì„¸ëŒ€ìˆ˜" in sorted_df.columns:
            display_columns.append("ì „ìš©ë©´ì 60_85ã¡_ì„¸ëŒ€ìˆ˜")
        if "ì „ìš©ë©´ì 85_135ã¡_ì„¸ëŒ€ìˆ˜" in sorted_df.columns:
            display_columns.append("ì „ìš©ë©´ì 85_135ã¡_ì„¸ëŒ€ìˆ˜")
        
        # ì£¼ì°¨ ì •ë³´
        if "ì£¼ì°¨ëŒ€ìˆ˜" in sorted_df.columns:
            display_columns.append("ì£¼ì°¨ëŒ€ìˆ˜")
        if "ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜" in sorted_df.columns:
            display_columns.append("ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜")
        
        # ì§€í•˜ì²  ì •ë³´
        if "ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­" in sorted_df.columns:
            display_columns.append("ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­")
        if "ì§€í•˜ì² ì—­ê±°ë¦¬_km" in sorted_df.columns:
            display_columns.append("ì§€í•˜ì² ì—­ê±°ë¦¬_km")
        
        # ì£¼ì†ŒëŠ” ë§¨ ìš°ì¸¡ì— ë°°ì¹˜
        if "ì£¼ì†Œ" in sorted_df.columns:
            display_columns.append("ì£¼ì†Œ")
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§
        display_columns = [col for col in display_columns if col in sorted_df.columns]
        
        # í‘œì‹œìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± (ì»¬ëŸ¼ëª… ê°„ëµí™” ë° í¬ë§·íŒ…)
        display_df = sorted_df[display_columns].copy()
        
        # ì»¬ëŸ¼ëª… ê°„ëµí™” ë§¤í•‘
        column_mapping = {
            "ìì¹˜êµ¬": "ìì¹˜êµ¬",
            "ë™": "ë™",
            "ì•„íŒŒíŠ¸ëª…": "ì•„íŒŒíŠ¸ëª…",
            "ì£¼ì†Œ": "ì£¼ì†Œ",
            "ê±´ì¶•ì—°ë„": "ì—°ë„",
            "ì„¸ëŒ€ìˆ˜": "ì„¸ëŒ€ìˆ˜",
            "ë³µë„ê³„ë‹¨ì‹": "ë³µë„/ê³„ë‹¨",
            "ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•": "í‰í˜•",
            "í‰ìˆ˜": "í‰ìˆ˜",
            "ì‹¤ê±°ë˜ê°€": "ì‹¤ê±°ë˜ê°€",
            "ê¸°ì¤€ì—°ì›”ì¼": "ê¸°ì¤€ì—°ì›”ì¼",
            "ì „ìš©ë©´ì 60ã¡ì´í•˜_ì„¸ëŒ€ìˆ˜": "60ã¡ì´í•˜",
            "ì „ìš©ë©´ì 60_85ã¡_ì„¸ëŒ€ìˆ˜": "60~85ã¡",
            "ì „ìš©ë©´ì 85_135ã¡_ì„¸ëŒ€ìˆ˜": "85~135ã¡",
            "ì£¼ì°¨ëŒ€ìˆ˜": "ì£¼ì°¨",
            "ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜": "ì„¸ëŒ€ë‹¹ì£¼ì°¨",
            "ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­": "ì§€í•˜ì² ì—­",
            "ì§€í•˜ì² ì—­ê±°ë¦¬_km": "ì—­ê±°ë¦¬"
        }
        
        # ì»¬ëŸ¼ëª… ë³€ê²½
        display_df = display_df.rename(columns=column_mapping)
        # ë§¤ì¹­ ì•ˆ ëœ í–‰: í‰ìˆ˜/ì‹¤ê±°ë˜ê°€/ê¸°ì¤€ì—°ì›”ì¼ ê³µë€ ì²˜ë¦¬
        for _col in ["í‰ìˆ˜", "ì‹¤ê±°ë˜ê°€", "ê¸°ì¤€ì—°ì›”ì¼"]:
            if _col in display_df.columns:
                display_df[_col] = display_df[_col].apply(lambda x: "" if pd.isna(x) else x)
        # ê±´ì¶•ì—°ë„ í¬ë§·íŒ… (ì½¤ë§ˆ ì œê±°, ì •ìˆ˜ë¡œ í‘œì‹œ)
        if "ì—°ë„" in display_df.columns:
            display_df["ì—°ë„"] = display_df["ì—°ë„"].apply(
                lambda x: str(int(x)) if pd.notna(x) else ""
            )
        
        st.dataframe(
            display_df,
            width="stretch",
            height=700,
            hide_index=True
        )
        
        # CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ê°„ëµí™”ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ)
        csv = display_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="seoul_apartments_filtered.csv",
            mime="text/csv"
        )
    
    with tab2:
        # ì§€ë„ ìƒì„±
        if len(filtered_df) > 0:
            # í•„í„°ë§ëœ ë°ì´í„°ì˜ ìœ íš¨í•œ ì¢Œí‘œë§Œ ì‚¬ìš©í•˜ì—¬ ì¤‘ì‹¬ì  ê³„ì‚°
            valid_coords = filtered_df[
                (filtered_df["ìœ„ë„"].notna()) & 
                (filtered_df["ê²½ë„"].notna())
            ]
            
            if len(valid_coords) > 0:
                # ì¤‘ì‹¬ì  ê³„ì‚°
                center_lat = valid_coords["ìœ„ë„"].mean()
                center_lon = valid_coords["ê²½ë„"].mean()
                
                # ë°ì´í„° ë²”ìœ„ ê³„ì‚°
                min_lat = valid_coords["ìœ„ë„"].min()
                max_lat = valid_coords["ìœ„ë„"].max()
                min_lon = valid_coords["ê²½ë„"].min()
                max_lon = valid_coords["ê²½ë„"].max()
                
                # ë²”ìœ„ì— ë”°ë¥¸ ì ì ˆí•œ ì´ˆê¸° ì¤Œ ë ˆë²¨ ê³„ì‚°
                lat_range = max_lat - min_lat
                lon_range = max_lon - min_lon
                max_range = max(lat_range, lon_range)
                
                # ë²”ìœ„ì— ë”°ë¥¸ ì ì ˆí•œ ì¤Œ ë ˆë²¨ ê³„ì‚°
                if max_range < 0.01:  # ë§¤ìš° ì¢ì€ ë²”ìœ„ (ì•½ 1km)
                    zoom_start = 15
                elif max_range < 0.05:  # ì¢ì€ ë²”ìœ„ (ì•½ 5km)
                    zoom_start = 13
                elif max_range < 0.1:  # ì¤‘ê°„ ë²”ìœ„ (ì•½ 10km)
                    zoom_start = 12
                elif max_range < 0.2:  # ë„“ì€ ë²”ìœ„ (ì•½ 20km)
                    zoom_start = 11
                else:  # ë§¤ìš° ë„“ì€ ë²”ìœ„
                    zoom_start = 10
            else:
                # ìœ íš¨í•œ ì¢Œí‘œê°€ ì—†ìœ¼ë©´ ì„œìš¸ ì¤‘ì‹¬ ì¢Œí‘œ ì‚¬ìš©
                center_lat = 37.5665
                center_lon = 126.9780
                zoom_start = 11
                min_lat = max_lat = min_lon = max_lon = None
            
            m = folium.Map(
                location=[center_lat, center_lon],
                zoom_start=zoom_start,
                tiles="OpenStreetMap"
            )
            
            # ë§ˆì»¤ ì¶”ê°€ (ìœ íš¨í•œ ì¢Œí‘œë§Œ)
            for idx, row in filtered_df.iterrows():
                # ì¢Œí‘œê°€ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ ë§ˆì»¤ ì¶”ê°€
                if pd.notna(row.get("ìœ„ë„")) and pd.notna(row.get("ê²½ë„")):
                    # ì•„íŒŒíŠ¸ëª…ì´ ìˆìœ¼ë©´ í¬í•¨
                    apt_name = row.get('ì•„íŒŒíŠ¸ëª…', '') or row.get('ì£¼ì†Œ', '')
                    popup_text = f"""
                    <b>{apt_name}</b><br>
                    ì£¼ì†Œ: {row.get('ì£¼ì†Œ', '')}<br>
                    ìì¹˜êµ¬: {row.get('ìì¹˜êµ¬', '')}<br>
                    ê±´ì¶•ì—°ë„: {row.get('ê±´ì¶•ì—°ë„', '')}ë…„<br>
                    ì„¸ëŒ€ìˆ˜: {row.get('ì„¸ëŒ€ìˆ˜', '')}ì„¸ëŒ€<br>
                    í‰í˜•: {row.get('í‰í˜•', '')}í‰<br>
                    ì§€í•˜ì² ì—­: {row.get('ê°€ì¥ê°€ê¹Œìš´ì§€í•˜ì² ì—­', '')} ({row.get('ì§€í•˜ì² ì—­ê±°ë¦¬_km', '')}km)
                    """
                    
                    # íˆ´íŒì— ì•„íŒŒíŠ¸ëª… ë˜ëŠ” ì£¼ì†Œ í‘œì‹œ
                    tooltip_text = row.get('ì•„íŒŒíŠ¸ëª…', '') or row.get('ì£¼ì†Œ', '')
                    folium.Marker(
                        [row["ìœ„ë„"], row["ê²½ë„"]],
                        popup=folium.Popup(popup_text, max_width=300),
                        tooltip=tooltip_text
                    ).add_to(m)
            
            # ëª¨ë“  ë§ˆì»¤ê°€ ë³´ì´ë„ë¡ bounds ì„¤ì • (ìœ íš¨í•œ ì¢Œí‘œê°€ ìˆëŠ” ê²½ìš°ë§Œ)
            if len(valid_coords) > 0 and min_lat is not None:
                padding = 0.01  # ì•½ 1km ì—¬ìœ  ê³µê°„
                m.fit_bounds(
                    [[min_lat - padding, min_lon - padding],
                     [max_lat + padding, max_lon + padding]],
                    padding=(20, 20)  # í”½ì…€ ë‹¨ìœ„ ì—¬ìœ  ê³µê°„
                )
            
            # ì§€ë„ ì¤‘ì•™ ì •ë ¬ì„ ìœ„í•œ ì»¬ëŸ¼ ì‚¬ìš©
            col1, col2, col3 = st.columns([1, 10, 1])
            with col2:
                st_folium(m, height=600, width="stretch")
        else:
            st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with tab3:
        st.info("ğŸ’¡ í†µê³„ëŠ” í•„í„°ë§ê³¼ ë¬´ê´€í•˜ê²Œ ì „ì²´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**ìì¹˜êµ¬ë³„ ì•„íŒŒíŠ¸ ìˆ˜**")
            # ì „ì²´ ë°ì´í„° ê¸°ì¤€
            district_counts = df["ìì¹˜êµ¬"].value_counts()
            st.bar_chart(district_counts)
        
        with col2:
            st.write("**ê±´ì¶•ì—°ë„ë³„ ë¶„í¬**")
            # ì „ì²´ ë°ì´í„° ê¸°ì¤€
            year_data = df["ê±´ì¶•ì—°ë„"].dropna()
            if len(year_data) > 0:
                year_counts = year_data.value_counts().sort_index()
                st.line_chart(year_counts)
        
        col3, col4 = st.columns(2)
        
        with col3:
            st.write("**ë³µë„/ê³„ë‹¨ì‹ ë¶„í¬**")
            # ì „ì²´ ë°ì´í„° ê¸°ì¤€
            hallway_data = df["ë³µë„ê³„ë‹¨ì‹"].dropna()
            if len(hallway_data) > 0:
                hallway_counts = hallway_data.value_counts()
                st.bar_chart(hallway_counts)
        
        with col4:
            st.write("**ì„¸ëŒ€ë‹¹ í‰í˜• ë¶„í¬**")
            # ì „ì²´ ë°ì´í„° ê¸°ì¤€
            if "ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•" in df.columns:
                pyeong_data = df["ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•"].dropna()
                if len(pyeong_data) > 0:
                    pyeong_counts = pd.cut(
                        pyeong_data,
                        bins=10,
                        labels=[f"{i*5}-{(i+1)*5}í‰" for i in range(10)]
                    ).value_counts().sort_index()
                    st.bar_chart(pyeong_counts)
        
        st.markdown("---")
        
        # ìì¹˜êµ¬ë³„ í†µê³„ ê³„ì‚° (ì „ì²´ ë°ì´í„° ê¸°ì¤€)
        if "ìì¹˜êµ¬" in df.columns:
            district_stats = []
            
            for district in sorted(df["ìì¹˜êµ¬"].dropna().unique()):
                district_data = df[df["ìì¹˜êµ¬"] == district]
                
                stats = {
                    "ìì¹˜êµ¬": district,
                    "ì•„íŒŒíŠ¸ ìˆ˜": len(district_data)
                }
                
                # í‰ê·  ê±´ì¶•ì—°ë„
                year_data = district_data["ê±´ì¶•ì—°ë„"].dropna()
                if len(year_data) > 0:
                    stats["í‰ê·  ê±´ì¶•ì—°ë„"] = f"{int(year_data.mean())}ë…„"
                else:
                    stats["í‰ê·  ê±´ì¶•ì—°ë„"] = "N/A"
                
                # í‰ê·  ì„¸ëŒ€ìˆ˜
                household_data = district_data["ì„¸ëŒ€ìˆ˜"].dropna()
                if len(household_data) > 0:
                    stats["í‰ê·  ì„¸ëŒ€ìˆ˜"] = f"{int(household_data.mean())}ì„¸ëŒ€"
                else:
                    stats["í‰ê·  ì„¸ëŒ€ìˆ˜"] = "N/A"
                
                # í‰ê·  í‰í˜• (ì„¸ëŒ€ë‹¹)
                if "ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•" in district_data.columns:
                    pyeong_data = district_data["ì„¸ëŒ€ë‹¹í‰ê· í‰í˜•"].dropna()
                    if len(pyeong_data) > 0:
                        stats["í‰ê·  í‰í˜• (ì„¸ëŒ€ë‹¹)"] = f"{pyeong_data.mean():.1f}í‰"
                    else:
                        stats["í‰ê·  í‰í˜• (ì„¸ëŒ€ë‹¹)"] = "N/A"
                elif "í‰í˜•" in district_data.columns:
                    pyeong_data = district_data["í‰í˜•"].dropna()
                    if len(pyeong_data) > 0:
                        stats["í‰ê·  í‰í˜•"] = f"{pyeong_data.mean():.1f}í‰"
                    else:
                        stats["í‰ê·  í‰í˜•"] = "N/A"
                
                # í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜
                if "ì£¼ì°¨ëŒ€ìˆ˜" in district_data.columns:
                    parking_data = district_data["ì£¼ì°¨ëŒ€ìˆ˜"].dropna()
                    if len(parking_data) > 0:
                        stats["í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜"] = f"{int(parking_data.mean())}ëŒ€"
                    else:
                        stats["í‰ê·  ì£¼ì°¨ëŒ€ìˆ˜"] = "N/A"
                
                # í‰ê·  ì„¸ëŒ€ë‹¹ ì£¼ì°¨ë©´ìˆ˜
                if "ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜" in district_data.columns:
                    parking_per_hh_data = district_data["ì„¸ëŒ€ë‹¹ì£¼ì°¨ë©´ìˆ˜"].dropna()
                    if len(parking_per_hh_data) > 0:
                        stats["í‰ê·  ì„¸ëŒ€ë‹¹ ì£¼ì°¨ë©´ìˆ˜"] = f"{parking_per_hh_data.mean():.2f}ë©´"
                    else:
                        stats["í‰ê·  ì„¸ëŒ€ë‹¹ ì£¼ì°¨ë©´ìˆ˜"] = "N/A"
                
                # í‰ê·  ì§€í•˜ì²  ê±°ë¦¬
                distance_data = district_data["ì§€í•˜ì² ì—­ê±°ë¦¬_km"].dropna()
                if len(distance_data) > 0:
                    stats["í‰ê·  ì§€í•˜ì²  ê±°ë¦¬"] = f"{distance_data.mean():.2f}km"
                else:
                    stats["í‰ê·  ì§€í•˜ì²  ê±°ë¦¬"] = "N/A"
                
                district_stats.append(stats)
            
            # í†µê³„ í…Œì´ë¸” ìƒì„±
            if district_stats:
                stats_df = pd.DataFrame(district_stats)
                st.dataframe(
                    stats_df,
                    width="stretch",
                    height=910,
                    hide_index=True
                )
                
                # CSV ë‹¤ìš´ë¡œë“œ
                csv_stats = stats_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ìì¹˜êµ¬ë³„ í†µê³„ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_stats,
                    file_name="district_statistics.csv",
                    mime="text/csv",
                    key="district_stats_download"
                )
else:
    st.warning("ì¡°ê±´ì— ë§ëŠ” ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ì£¼ì„¸ìš”.")

# ì‚¬ì´ë“œë°” í•˜ë‹¨
st.sidebar.markdown("---")
st.sidebar.markdown("### ë°ì´í„° ìƒˆë¡œê³ ì¹¨")

# Streamlit secretsì—ì„œ ë¹„ë°€ë²ˆí˜¸ í™•ì¸ (TOMLì—ì„œ ìˆ«ìë¡œ ë“¤ì–´ì˜¤ë©´ ë¬¸ìì—´ë¡œ í†µì¼)
required_password = str(st.secrets.get("data_password", "1234")).strip()

# ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
password_input = st.sidebar.text_input("ë¹„ë°€ë²ˆí˜¸ ì…ë ¥", type="password", key="data_password_input")
password_ok = password_input and (password_input.strip() == required_password)

if st.sidebar.button("ìƒˆ ë°ì´í„° ìƒì„±"):
    if password_ok:
        with st.sidebar:
            with st.status("ğŸŒ ì„œìš¸ ì—´ë¦°ë°ì´í„°ê´‘ì¥ APIì—ì„œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", expanded=True) as status:
                try:
                    crawler = SeoulApartmentCrawler()
                    
                    # ë¨¼ì € ì‘ì€ ë²”ìœ„ë¡œ í…ŒìŠ¤íŠ¸
                    st.write("ğŸ“¡ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘... (1~100ê±´)")
                    test_df = crawler.crawl_seoul_apartment_info(1, 100)
                    
                    if not test_df.empty:
                        st.write(f"API í…ŒìŠ¤íŠ¸ ì„±ê³µ! {len(test_df)}ê±´ ìˆ˜ì§‘")
                        st.write("ğŸ“¥ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (1000ê°œì”© ë°°ì¹˜)...")
                        
                        # ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (5000ê°œë¡œ ì œí•œí•˜ì—¬ ì‹œê°„ ë‹¨ì¶•)
                        all_df = crawler.crawl_seoul_apartment_info_all(max_records=5000)
                        
                        if not all_df.empty:
                            st.write("ğŸ”„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
                            processed_df = crawler.process_seoul_apartment_info_data(all_df)
                            df_fresh = preprocess_apartment_df(processed_df)

                            # ì„¸ì…˜ì— ì €ì¥ â†’ ìƒˆë¡œê³ ì¹¨ ì‹œ load_data()ê°€ ì´ê±¸ ìµœìš°ì„  ì‚¬ìš© (Cloudì—ì„œë„ ë™ì‘)
                            st.session_state[SESSION_KEY_APARTMENT_DATA] = df_fresh

                            try:
                                crawler.save_to_csv(processed_df, "seoul_apartments_metadata.csv")
                            except Exception:
                                pass

                            load_data.clear()
                            status.update(label=f"âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! (ì´ {len(df_fresh)}ê±´)", state="complete")
                            st.success(f"ì‹¤ì œ ì•„íŒŒíŠ¸ ë©”íƒ€ë°ì´í„° {len(df_fresh)}ê±´ì´ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.info("ğŸ”„ í™”ë©´ì´ ìƒˆë¡œê³ ì¹¨ë˜ë©° ìƒˆë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
                            st.rerun()
                        else:
                            status.update(label="âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨", state="error")
                            st.error("âŒ ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                    else:
                        status.update(label="âŒ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨", state="error")
                        st.error("âŒ API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        st.info("ğŸ’¡ API í‚¤ëŠ” .env íŒŒì¼ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— SEOUL_DATA_API_KEYë¡œ ì„¤ì •í•˜ì„¸ìš”.")
                        
                except Exception as e:
                    status.update(label="âŒ ì˜¤ë¥˜ ë°œìƒ", state="error")
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    st.info("ğŸ’¡ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    else:
        st.sidebar.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

